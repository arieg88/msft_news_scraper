{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore a dataset of financial articles scraped from Yahoo Finance. The primary goal is to analyze the sentiment of these articles and derive meaningful insights from the textual data. We will perform the following steps:\n",
    "\n",
    "1. **Imports**: We will import the necessary libraries and modules required for data manipulation, natural language processing, and sentiment analysis. This includes libraries for web scraping, data handling, sentiment analysis, and visualization.\n",
    "\n",
    "2. **Data Loading**: We will load the dataset containing the scraped articles, which are stored in JSON format. This dataset comprises various financial topics, allowing us to conduct a comprehensive sentiment analysis.\n",
    "\n",
    "3. **Data Cleaning and Preprocessing**: The loaded data will undergo several preprocessing steps, including:\n",
    "   - Removing duplicates and handling missing values.\n",
    "   - Cleaning the text by removing URLs, special characters, and stop words.\n",
    "   - Converting dates to the appropriate format for analysis.\n",
    "\n",
    "4. **Sentiment Analysis**: We will utilize Natural Language Processing (NLP) techniques to analyze the sentiment of the articles. This will involve:\n",
    "   - Applying the VADER sentiment analysis tool for initial scoring.\n",
    "   - Leveraging pre-trained transformer models, such as FinBERT, to gain deeper insights into the sentiment conveyed in the articles.\n",
    "\n",
    "5. **Entity and Emotion Extraction**: Using SpaCy and NRC Lexicon, we will extract entities and associated emotions from the text to enrich our analysis further.\n",
    "\n",
    "6. **Data Visualization and Reporting**: Finally, we will visualize the sentiment scores and present the findings in a structured format, allowing for an easier interpretation of the financial sentiment trends over time.\n",
    "\n",
    "By the end of this notebook, we aim to obtain a consolidated DataFrame that captures essential information and insights derived from the financial articles, paving the way for informed decision-making in financial contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "In this section, we import essential libraries for data processing and analysis. Key libraries include:\n",
    "- **Requests** and **BeautifulSoup** for web scraping.\n",
    "- **Pandas** and **NumPy** for data manipulation and numerical operations.\n",
    "- **NLTK** for natural language processing tasks, including sentiment analysis with VADER.\n",
    "- **Transformers** for advanced NLP models like BART for summarization.\n",
    "- **SpaCy** for efficient entity extraction.\n",
    "- **nrclex** for emotion analysis based on the NRC lexicon.\n",
    "- **BERTopic** and **SentenceTransformers** for topic modeling and semantic similarity.\n",
    "\n",
    "These libraries form the backbone of our analysis workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSzUZvw73ckb",
    "outputId": "600172eb-703a-4c1f-8930-d3de985d1419"
   },
   "outputs": [],
   "source": [
    "# ! pip install pandas numpy dash dash-bootstrap-components plotly wordcloud matplotlib nltk textblob nrclex bertopic sentence_transformers transformers bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RsLxbLe6D7ro"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "from nrclex import NRCLex\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvmJAgQe371D",
    "outputId": "92221f6b-66be-4637-d145-7fee97c4d52b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Arie\n",
      "[nltk_data]     Gruber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Arie\n",
      "[nltk_data]     Gruber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Arie\n",
      "[nltk_data]     Gruber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Arie\n",
      "[nltk_data]     Gruber\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the 'stopwords' corpus\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Optionally, download 'punkt' if you haven't already\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "In this section, we load the dataset containing scraped articles from Yahoo Finance, specifically focusing on Microsoft. The dataset features the following columns: **Date**, **Title**, **Author**, and **Text**. It encompasses articles from January 2024 to mid-October 2024. After completing the data cleaning process in this notebook, we expect to have 1,083 unique articles for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "OBYmzAJkbmHT",
    "outputId": "e284ebe3-b7ec-4921-9358-ec848639e10d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-31 11:56:19+00:00</td>\n",
       "      <td>Microsoft beats Q2 earnings on AI, cloud strength</td>\n",
       "      <td>Daniel Howley    路 Technology Editor</td>\n",
       "      <td>Microsoft (MSFT) announced its second quarter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-03 15:00:00+00:00</td>\n",
       "      <td>If You Invested $10,000 in Microsoft When Saty...</td>\n",
       "      <td>Jeremy Bowman, The Motley Fool</td>\n",
       "      <td>Microsoft (NASDAQ: MSFT) is back on top of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-09 11:00:00+00:00</td>\n",
       "      <td>Why Microsoft Stock Rallied 57% in 2023</td>\n",
       "      <td>Danny Vena, The Motley Fool</td>\n",
       "      <td>Shares of Microsoft (NASDAQ: MSFT) charged sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-30 21:35:57+00:00</td>\n",
       "      <td>Microsoft Corp (MSFT) Reports Robust Growth wi...</td>\n",
       "      <td>GuruFocus Research</td>\n",
       "      <td>Revenue: $62.0 billion, an 18% increase year-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-04 08:01:09+00:00</td>\n",
       "      <td>Microsoft is adding an AI button to PC keyboar...</td>\n",
       "      <td>Daniel Howley    路 Technology Editor</td>\n",
       "      <td>Microsoft (MSFT) is doubling down on its commi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0 2024-01-31 11:56:19+00:00   \n",
       "1 2024-01-03 15:00:00+00:00   \n",
       "2 2024-01-09 11:00:00+00:00   \n",
       "3 2024-01-30 21:35:57+00:00   \n",
       "4 2024-01-04 08:01:09+00:00   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Microsoft beats Q2 earnings on AI, cloud strength   \n",
       "1  If You Invested $10,000 in Microsoft When Saty...   \n",
       "2            Why Microsoft Stock Rallied 57% in 2023   \n",
       "3  Microsoft Corp (MSFT) Reports Robust Growth wi...   \n",
       "4  Microsoft is adding an AI button to PC keyboar...   \n",
       "\n",
       "                                  Author  \\\n",
       "0   Daniel Howley    路 Technology Editor   \n",
       "1        Jeremy Bowman, The Motley Fool    \n",
       "2           Danny Vena, The Motley Fool    \n",
       "3                    GuruFocus Research    \n",
       "4   Daniel Howley    路 Technology Editor   \n",
       "\n",
       "                                                Text  \n",
       "0  Microsoft (MSFT) announced its second quarter ...  \n",
       "1  Microsoft (NASDAQ: MSFT) is back on top of the...  \n",
       "2  Shares of Microsoft (NASDAQ: MSFT) charged sha...  \n",
       "3  Revenue: $62.0 billion, an 18% increase year-o...  \n",
       "4  Microsoft (MSFT) is doubling down on its commi...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for month in range(1, 11):\n",
    "  path = f'./articles/2024/{month}_articles.json'\n",
    "  df = pd.concat([df, pd.read_json(path)])\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we focus on cleaning and preprocessing the dataset to ensure it is ready for analysis. The first step involves converting the **Date** column into a datetime format to facilitate time-based operations. After sorting the DataFrame by the date, we remove any duplicate entries based on the **Title** and **Date** columns, ensuring each article is unique. We also drop any rows with missing values and reset the index for a clean DataFrame. Finally, we extract the month from the date for potential grouping and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "CwG9DFkseB8P",
    "outputId": "885e9d24-d131-4413-a675-a4cb9a83bfa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before removing duplicates(1491, 4)\n",
      "shape after removing duplicates(1083, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 12:00:27+00:00</td>\n",
       "      <td>Investors in Microsoft (NASDAQ:MSFT) have seen...</td>\n",
       "      <td>editorial-team@simplywallst.com (Simply Wall...</td>\n",
       "      <td>The most you can lose on any stock (assuming y...</td>\n",
       "      <td>2024-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02 15:09:36+00:00</td>\n",
       "      <td>Best AI Stock 2024: Alphabet Stock vs. Microso...</td>\n",
       "      <td>Parkev Tatevosian, CFA, The Motley Fool</td>\n",
       "      <td>Fool.com contributor Parkev Tatevosian compare...</td>\n",
       "      <td>2024-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03 14:42:51+00:00</td>\n",
       "      <td>1 Artificial Intelligence (AI) Stock Poised to...</td>\n",
       "      <td>Parkev Tatevosian, CFA, The Motley Fool</td>\n",
       "      <td>Fool.com contributor Parkev Tatevosian highlig...</td>\n",
       "      <td>2024-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-03 15:00:00+00:00</td>\n",
       "      <td>If You Invested $10,000 in Microsoft When Saty...</td>\n",
       "      <td>Jeremy Bowman, The Motley Fool</td>\n",
       "      <td>Microsoft (NASDAQ: MSFT) is back on top of the...</td>\n",
       "      <td>2024-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-03 15:29:29+00:00</td>\n",
       "      <td>Microsoft Copilot is now available on iOS and ...</td>\n",
       "      <td>Aisha Malik</td>\n",
       "      <td>Over the holiday season, Microsoft quietly lau...</td>\n",
       "      <td>2024-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0 2024-01-01 12:00:27+00:00   \n",
       "1 2024-01-02 15:09:36+00:00   \n",
       "2 2024-01-03 14:42:51+00:00   \n",
       "3 2024-01-03 15:00:00+00:00   \n",
       "4 2024-01-03 15:29:29+00:00   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Investors in Microsoft (NASDAQ:MSFT) have seen...   \n",
       "1  Best AI Stock 2024: Alphabet Stock vs. Microso...   \n",
       "2  1 Artificial Intelligence (AI) Stock Poised to...   \n",
       "3  If You Invested $10,000 in Microsoft When Saty...   \n",
       "4  Microsoft Copilot is now available on iOS and ...   \n",
       "\n",
       "                                              Author  \\\n",
       "0    editorial-team@simplywallst.com (Simply Wall...   \n",
       "1           Parkev Tatevosian, CFA, The Motley Fool    \n",
       "2           Parkev Tatevosian, CFA, The Motley Fool    \n",
       "3                    Jeremy Bowman, The Motley Fool    \n",
       "4                                       Aisha Malik    \n",
       "\n",
       "                                                Text    Month  \n",
       "0  The most you can lose on any stock (assuming y...  2024-01  \n",
       "1  Fool.com contributor Parkev Tatevosian compare...  2024-01  \n",
       "2  Fool.com contributor Parkev Tatevosian highlig...  2024-01  \n",
       "3  Microsoft (NASDAQ: MSFT) is back on top of the...  2024-01  \n",
       "4  Over the holiday season, Microsoft quietly lau...  2024-01  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the DataFrame by the 'Date' column\n",
    "df = df.sort_values(by='Date')\n",
    "print('shape before removing duplicates' +str(df.shape))\n",
    "# Remove duplicate rows based on 'Title' and 'Date'\n",
    "df = df.drop_duplicates(subset=['Title', 'Date'])\n",
    "df.dropna(inplace=True)\n",
    "# Optionally, reset the index if you want a clean index after dropping duplicates\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('shape after removing duplicates' +str(df.shape))\n",
    "# Extract month for grouping\n",
    "df['Month'] = df['Date'].dt.to_period('M')\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1083 entries, 0 to 1082\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype              \n",
      "---  ------  --------------  -----              \n",
      " 0   Date    1083 non-null   datetime64[ns, UTC]\n",
      " 1   Title   1083 non-null   object             \n",
      " 2   Author  1083 non-null   object             \n",
      " 3   Text    1083 non-null   object             \n",
      " 4   Month   1083 non-null   period[M]          \n",
      "dtypes: datetime64[ns, UTC](1), object(3), period[M](1)\n",
      "memory usage: 42.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning\n",
    "\n",
    "In the upcoming cell, we define a function to clean the text data in the **Text** column of our DataFrame. This function aims to remove any URLs, special characters, numbers, and excessive whitespace from the text. Additionally, all text is converted to lowercase to standardize it, making it easier to analyze later. The cleaned text will be stored in a new column, **clean_content_context**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "6Gd5nW-V2gH_",
    "outputId": "f99e9add-7691-4889-93e5-740ee956a328"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "      <th>Month</th>\n",
       "      <th>clean_content_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 12:00:27+00:00</td>\n",
       "      <td>Investors in Microsoft (NASDAQ:MSFT) have seen...</td>\n",
       "      <td>editorial-team@simplywallst.com (Simply Wall...</td>\n",
       "      <td>The most you can lose on any stock (assuming y...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>the most you can lose on any stock assuming yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02 15:09:36+00:00</td>\n",
       "      <td>Best AI Stock 2024: Alphabet Stock vs. Microso...</td>\n",
       "      <td>Parkev Tatevosian, CFA, The Motley Fool</td>\n",
       "      <td>Fool.com contributor Parkev Tatevosian compare...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>foolcom contributor parkev tatevosian compares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03 14:42:51+00:00</td>\n",
       "      <td>1 Artificial Intelligence (AI) Stock Poised to...</td>\n",
       "      <td>Parkev Tatevosian, CFA, The Motley Fool</td>\n",
       "      <td>Fool.com contributor Parkev Tatevosian highlig...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>foolcom contributor parkev tatevosian highligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-03 15:00:00+00:00</td>\n",
       "      <td>If You Invested $10,000 in Microsoft When Saty...</td>\n",
       "      <td>Jeremy Bowman, The Motley Fool</td>\n",
       "      <td>Microsoft (NASDAQ: MSFT) is back on top of the...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>microsoft nasdaq msft is back on top of the te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-03 15:29:29+00:00</td>\n",
       "      <td>Microsoft Copilot is now available on iOS and ...</td>\n",
       "      <td>Aisha Malik</td>\n",
       "      <td>Over the holiday season, Microsoft quietly lau...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>over the holiday season microsoft quietly laun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0 2024-01-01 12:00:27+00:00   \n",
       "1 2024-01-02 15:09:36+00:00   \n",
       "2 2024-01-03 14:42:51+00:00   \n",
       "3 2024-01-03 15:00:00+00:00   \n",
       "4 2024-01-03 15:29:29+00:00   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Investors in Microsoft (NASDAQ:MSFT) have seen...   \n",
       "1  Best AI Stock 2024: Alphabet Stock vs. Microso...   \n",
       "2  1 Artificial Intelligence (AI) Stock Poised to...   \n",
       "3  If You Invested $10,000 in Microsoft When Saty...   \n",
       "4  Microsoft Copilot is now available on iOS and ...   \n",
       "\n",
       "                                              Author  \\\n",
       "0    editorial-team@simplywallst.com (Simply Wall...   \n",
       "1           Parkev Tatevosian, CFA, The Motley Fool    \n",
       "2           Parkev Tatevosian, CFA, The Motley Fool    \n",
       "3                    Jeremy Bowman, The Motley Fool    \n",
       "4                                       Aisha Malik    \n",
       "\n",
       "                                                Text    Month  \\\n",
       "0  The most you can lose on any stock (assuming y...  2024-01   \n",
       "1  Fool.com contributor Parkev Tatevosian compare...  2024-01   \n",
       "2  Fool.com contributor Parkev Tatevosian highlig...  2024-01   \n",
       "3  Microsoft (NASDAQ: MSFT) is back on top of the...  2024-01   \n",
       "4  Over the holiday season, Microsoft quietly lau...  2024-01   \n",
       "\n",
       "                               clean_content_context  \n",
       "0  the most you can lose on any stock assuming yo...  \n",
       "1  foolcom contributor parkev tatevosian compares...  \n",
       "2  foolcom contributor parkev tatevosian highligh...  \n",
       "3  microsoft nasdaq msft is back on top of the te...  \n",
       "4  over the holiday season microsoft quietly laun...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove URLs, special characters, numbers, and extra spaces\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#','', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df['clean_content_context'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words Removal\n",
    "\n",
    "In this section, we address the removal of stop words from the cleaned text. Stop words are common words (like \"and,\" \"the,\" \"is,\" etc.) that may not contribute significant meaning to the analysis. By eliminating these words, we aim to enhance the quality of our textual data and focus on more informative terms. The cleaned text without stop words will be stored in a new column, **clean_content_no_stopwords**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "fdvJsXq0-rS_",
    "outputId": "b5f63635-09f2-47d7-81b0-842c7d688f8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "      <th>Month</th>\n",
       "      <th>clean_content_context</th>\n",
       "      <th>clean_content_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 12:00:27+00:00</td>\n",
       "      <td>Investors in Microsoft (NASDAQ:MSFT) have seen...</td>\n",
       "      <td>editorial-team@simplywallst.com (Simply Wall...</td>\n",
       "      <td>The most you can lose on any stock (assuming y...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>the most you can lose on any stock assuming yo...</td>\n",
       "      <td>lose stock assuming dont use leverage money br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02 15:09:36+00:00</td>\n",
       "      <td>Best AI Stock 2024: Alphabet Stock vs. Microso...</td>\n",
       "      <td>Parkev Tatevosian, CFA, The Motley Fool</td>\n",
       "      <td>Fool.com contributor Parkev Tatevosian compare...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>foolcom contributor parkev tatevosian compares...</td>\n",
       "      <td>foolcom contributor parkev tatevosian compares...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03 14:42:51+00:00</td>\n",
       "      <td>1 Artificial Intelligence (AI) Stock Poised to...</td>\n",
       "      <td>Parkev Tatevosian, CFA, The Motley Fool</td>\n",
       "      <td>Fool.com contributor Parkev Tatevosian highlig...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>foolcom contributor parkev tatevosian highligh...</td>\n",
       "      <td>foolcom contributor parkev tatevosian highligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-03 15:00:00+00:00</td>\n",
       "      <td>If You Invested $10,000 in Microsoft When Saty...</td>\n",
       "      <td>Jeremy Bowman, The Motley Fool</td>\n",
       "      <td>Microsoft (NASDAQ: MSFT) is back on top of the...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>microsoft nasdaq msft is back on top of the te...</td>\n",
       "      <td>microsoft nasdaq msft back top tech world days...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-03 15:29:29+00:00</td>\n",
       "      <td>Microsoft Copilot is now available on iOS and ...</td>\n",
       "      <td>Aisha Malik</td>\n",
       "      <td>Over the holiday season, Microsoft quietly lau...</td>\n",
       "      <td>2024-01</td>\n",
       "      <td>over the holiday season microsoft quietly laun...</td>\n",
       "      <td>holiday season microsoft quietly launched copi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  \\\n",
       "0 2024-01-01 12:00:27+00:00   \n",
       "1 2024-01-02 15:09:36+00:00   \n",
       "2 2024-01-03 14:42:51+00:00   \n",
       "3 2024-01-03 15:00:00+00:00   \n",
       "4 2024-01-03 15:29:29+00:00   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Investors in Microsoft (NASDAQ:MSFT) have seen...   \n",
       "1  Best AI Stock 2024: Alphabet Stock vs. Microso...   \n",
       "2  1 Artificial Intelligence (AI) Stock Poised to...   \n",
       "3  If You Invested $10,000 in Microsoft When Saty...   \n",
       "4  Microsoft Copilot is now available on iOS and ...   \n",
       "\n",
       "                                              Author  \\\n",
       "0    editorial-team@simplywallst.com (Simply Wall...   \n",
       "1           Parkev Tatevosian, CFA, The Motley Fool    \n",
       "2           Parkev Tatevosian, CFA, The Motley Fool    \n",
       "3                    Jeremy Bowman, The Motley Fool    \n",
       "4                                       Aisha Malik    \n",
       "\n",
       "                                                Text    Month  \\\n",
       "0  The most you can lose on any stock (assuming y...  2024-01   \n",
       "1  Fool.com contributor Parkev Tatevosian compare...  2024-01   \n",
       "2  Fool.com contributor Parkev Tatevosian highlig...  2024-01   \n",
       "3  Microsoft (NASDAQ: MSFT) is back on top of the...  2024-01   \n",
       "4  Over the holiday season, Microsoft quietly lau...  2024-01   \n",
       "\n",
       "                               clean_content_context  \\\n",
       "0  the most you can lose on any stock assuming yo...   \n",
       "1  foolcom contributor parkev tatevosian compares...   \n",
       "2  foolcom contributor parkev tatevosian highligh...   \n",
       "3  microsoft nasdaq msft is back on top of the te...   \n",
       "4  over the holiday season microsoft quietly laun...   \n",
       "\n",
       "                          clean_content_no_stopwords  \n",
       "0  lose stock assuming dont use leverage money br...  \n",
       "1  foolcom contributor parkev tatevosian compares...  \n",
       "2  foolcom contributor parkev tatevosian highligh...  \n",
       "3  microsoft nasdaq msft back top tech world days...  \n",
       "4  holiday season microsoft quietly launched copi...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df['clean_content_no_stopwords'] = df['clean_content_context'].apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1083 entries, 0 to 1082\n",
      "Data columns (total 7 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   Date                        1083 non-null   datetime64[ns, UTC]\n",
      " 1   Title                       1083 non-null   object             \n",
      " 2   Author                      1083 non-null   object             \n",
      " 3   Text                        1083 non-null   object             \n",
      " 4   Month                       1083 non-null   period[M]          \n",
      " 5   clean_content_context       1083 non-null   object             \n",
      " 6   clean_content_no_stopwords  1083 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), object(5), period[M](1)\n",
      "memory usage: 59.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment and Emotion Analysis of Financial News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool particularly well-suited for analyzing sentiments expressed in social media and news articles. It is effective for short texts and accounts for the nuances of language, including emoticons, slang, and common expressions. In our analysis, we use VADER to evaluate the sentiments in the online news articles we scraped from Yahoo Finance, as it provides quick and reliable sentiment scores for financial texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mofUyaBg-vMf",
    "outputId": "407c8b8d-74c0-4f5b-bbdc-7b9be72e867d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.9869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound\n",
       "0  0.026  0.752  0.222    0.9994\n",
       "1  0.082  0.834  0.084    0.3612\n",
       "2  0.083  0.832  0.084    0.0772\n",
       "3  0.062  0.789  0.149    0.9976\n",
       "4  0.014  0.867  0.119    0.9869"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment_scores(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentiment_scores = {}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        score = sia.polarity_scores(sentence)\n",
    "        for sentiment in score:\n",
    "          sentiment_scores[sentiment] = score[sentiment]\n",
    "\n",
    "    return sentiment_scores\n",
    "\n",
    "vader_sentiments_list = list(df['clean_content_context'].apply(get_vader_sentiment_scores).values)\n",
    "vader_sentiments_df = pd.DataFrame(vader_sentiments_list)\n",
    "vader_sentiments_df.dropna(inplace=True)\n",
    "\n",
    "vader_sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zE9gDh13evxa",
    "outputId": "90e375f9-c30e-4829-deb0-793364d48559"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1083, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_sentiments_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with FinBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FinBERT is a pre-trained transformer-based model fine-tuned specifically for financial sentiment analysis. It provides a deeper understanding of sentiments in financial texts by leveraging the contextual information that transformer models offer. This is particularly important for our analysis of Yahoo Finance articles, as financial language often contains industry-specific terminology and nuanced meanings that traditional sentiment analysis tools might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BF67sNVFyoJU"
   },
   "outputs": [],
   "source": [
    "# Initialize FinBERT pipeline for sentiment analysis using a model fine-tuned for financial text\n",
    "try:\n",
    "    finbert_pipeline = pipeline(\"sentiment-analysis\", model=\"yiyanghkust/finbert-tone\", tokenizer=\"yiyanghkust/finbert-tone\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading FinBERT model: {e}\")\n",
    "\n",
    "def get_finbert_sentiment_scores(text):\n",
    "    \"\"\"\n",
    "    Function to compute FinBERT sentiment scores on financial text.\n",
    "    It splits the text into sentences and handles cases where sentences are too long for the model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input financial text to analyze.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing sentiment scores for each sentence.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Tokenize the text into individual sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        finbert_scores = []\n",
    "\n",
    "        # Iterate over sentences for sentiment analysis\n",
    "        for sentence in sentences:\n",
    "            # If the sentence is too long, split it into smaller chunks of 512 characters\n",
    "            if len(sentence) > 512:\n",
    "                chunks = [sentence[i:i + 512] for i in range(0, len(sentence), 512)]\n",
    "                for chunk in chunks:\n",
    "                    try:\n",
    "                        result = finbert_pipeline(chunk)\n",
    "                        finbert_scores.append(result[0])  # Store the result of each chunk\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error analyzing chunk: {chunk[:30]}... -> {e}\")\n",
    "            else:\n",
    "                # Analyze normally if the sentence is within the 512-character limit\n",
    "                try:\n",
    "                    result = finbert_pipeline(sentence)\n",
    "                    finbert_scores.append(result[0])  # Store the result for each sentence\n",
    "                except Exception as e:\n",
    "                    print(f\"Error analyzing sentence: {sentence[:30]}... -> {e}\")\n",
    "\n",
    "        return finbert_scores\n",
    "    except Exception as e:\n",
    "        print(f\"Error during sentiment analysis: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example: Apply the function to a dataframe column containing financial text\n",
    "# df['finbert_sentiments'] = df['clean_content_context'].apply(get_finbert_sentiment_scores)\n",
    "finbert = df['clean_content_context'].apply(get_finbert_sentiment_scores)\n",
    "finbert.dropna(inplace=True)\n",
    "\n",
    "finbert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Sentiment Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the mean sentiment scores provides a consolidated view of the overall sentiment expressed in the articles. This step is crucial to understand general trends in the financial news sentiment over time. By averaging the sentiment scores, we can easily assess whether the overall tone of the articles is predominantly positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "VfA3CRnG0eHb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.989776</td>\n",
       "      <td>0.999763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.962712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992111</td>\n",
       "      <td>0.951249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label  Negative   Neutral  Positive\n",
       "0      0.000000  0.995125  0.999990\n",
       "1      0.000000  0.989776  0.999763\n",
       "2      0.000000  0.999922  0.962712\n",
       "3      0.956777  0.999995  0.999816\n",
       "4      0.000000  0.992111  0.951249"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to return a DataFrame with mean scores for each label\n",
    "def get_mean_scores_df(label_list, labels=['Negative', 'Neutral', 'Positive']):\n",
    "    # Convert the list of dictionaries to DataFrame\n",
    "    row_data = pd.DataFrame(label_list).groupby('label').mean().T\n",
    "\n",
    "    # Ensure all columns (labels) are present, and fill missing ones with 0\n",
    "    for label in labels:\n",
    "        if label not in row_data.columns:\n",
    "            row_data[label] = 0\n",
    "\n",
    "    # Reorder the columns to match the desired order (only if they exist in the data)\n",
    "    row_data = row_data[[label for label in labels if label in row_data.columns]]\n",
    "\n",
    "    return row_data\n",
    "\n",
    "# Adjust apply calls for each model, with appropriate labels\n",
    "finbert_mean_df = pd.concat(finbert.apply(lambda x: get_mean_scores_df(x)).tolist(), ignore_index=True)\n",
    "finbert_mean_df.dropna(inplace=True)\n",
    "\n",
    "finbert_mean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization Using Bart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BART (Bidirectional and Auto-Regressive Transformers) is a transformer model designed for various natural language processing tasks, including text summarization. It effectively generates coherent and contextually relevant summaries from long documents. In our project, we utilize BART to distill the essential information from the financial news articles, allowing us to focus on the main insights without wading through extensive text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bart_limit = 512\n",
    "\n",
    "def get_summary(article):\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    \n",
    "    if len(article.split()) > bart_limit:\n",
    "        summaries = []\n",
    "        # for index in range(0, len(article.split()), bart_limit):\n",
    "        summaries = summarizer([article[index:index+bart_limit] for index in range(0,len(article.split()), bart_limit)]\n",
    "                               , max_length=100)\n",
    "        return ' '.join([summary['summary_text'] for summary in summaries]).strip()\n",
    "    else:\n",
    "        return summarizer(article, max_length=130)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 100, but your input_length is only 92. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 100, but your input_length is only 94. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 100, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 100, but your input_length is only 95. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 100, but your input_length is only 95. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 100, but your input_length is only 78. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\n",
      "Your max_length is set to 100, but your input_length is only 92. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 100, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 100, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 100, but your input_length is only 93. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 100, but your input_length is only 98. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n",
      "Your max_length is set to 100, but your input_length is only 98. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n",
      "Your max_length is set to 100, but your input_length is only 98. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n",
      "Your max_length is set to 100, but your input_length is only 95. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 100, but your input_length is only 90. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n",
      "Your max_length is set to 100, but your input_length is only 93. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 100, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 100, but your input_length is only 93. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 100, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 100, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 100, but your input_length is only 98. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bart_limit = 512\n",
    "\n",
    "def get_summary(article):\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    \n",
    "    if len(article.split()) > bart_limit:\n",
    "        summaries = []\n",
    "        # for index in range(0, len(article.split()), bart_limit):\n",
    "        summaries = summarizer([article[index:index+bart_limit] for index in range(0,len(article.split()), bart_limit)]\n",
    "                               , max_length=100)\n",
    "        return ' '.join([summary['summary_text'] for summary in summaries])\n",
    "    else:\n",
    "        return summarizer(article, max_length=130)\n",
    "\n",
    "# Create the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", max_length=130)\n",
    "    \n",
    "# Ensure that the input data is a string\n",
    "df['clean_content_context'] = df['clean_content_context'].astype(str)\n",
    "\n",
    "# Summarize the text and reate a DataFrame for summaries\n",
    "summary_df = pd.DataFrame(df['clean_content_context'].apply(get_summary)).rename({'clean_content_context': 'Summary'}, axis=1)\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity and Emotion Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain deeper insights into the emotional landscape of the articles, we apply techniques to extract entities and emotions. This step enriches our analysis by identifying key entities mentioned in the articles and understanding the emotions expressed about these entities. This nuanced understanding can aid in more targeted sentiment analysis and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install spacy\n",
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "frS9z39pDOFa"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nrclex import NRCLex\n",
    "\n",
    "# Load SpaCy model (ensure you have it installed, e.g., 'en_core_web_sm')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_entities_and_emotions(text):\n",
    "    doc = nlp(text)\n",
    "    results = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        sent_text = sent.text\n",
    "        entities = [ent.text for ent in sent.ents]\n",
    "        emotions = NRCLex(sent_text).raw_emotion_scores\n",
    "        results.append({\n",
    "            'sentence': sent_text,\n",
    "            'entities': entities,\n",
    "            'emotions': emotions\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# df['entities_and_emotions'] = df['clean_content_context'].apply(extract_entities_and_emotions)\n",
    "entities_and_emotions = df['clean_content_no_stopwords'].apply(extract_entities_and_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "L8HbMOFiYEGO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>joy</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  disgust  fear  negative  sadness  surprise  positive  anticipation  \\\n",
       "0    2.0      2.0   5.0       6.0      3.0       3.0      49.0          29.0   \n",
       "1    1.0      6.0   1.0      10.0      0.0       1.0       9.0           6.0   \n",
       "2    1.0      6.0   3.0      11.0      0.0       1.0      13.0           6.0   \n",
       "3    4.0      7.0   6.0      20.0      5.0       6.0      36.0          15.0   \n",
       "4    0.0      0.0   3.0       0.0      0.0       0.0      24.0          16.0   \n",
       "\n",
       "    joy  trust  \n",
       "0  25.0   35.0  \n",
       "1   2.0    6.0  \n",
       "2   4.0    9.0  \n",
       "3   7.0   20.0  \n",
       "4   7.0    4.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_emotions(row):\n",
    "    # Initialize an empty dictionary to store sums of emotions\n",
    "    summed_emotions = {}\n",
    "    count = len(row)  # Number of dictionaries in the row\n",
    "\n",
    "    # Loop through each index in the row\n",
    "    for index in range(count):  # Assuming row is a list of dictionaries\n",
    "        emotions_dict = row[index]['emotions']  # Extract the emotions dictionary\n",
    "\n",
    "        # Add up emotion values, initializing keys if they don't exist yet\n",
    "        for emotion, value in emotions_dict.items():\n",
    "            if emotion in summed_emotions:\n",
    "                summed_emotions[emotion] += value\n",
    "            else:\n",
    "                summed_emotions[emotion] = value\n",
    "\n",
    "    # Calculate the mean by dividing the summed values by the number of entries\n",
    "    mean_emotions = {emotion: value / count for emotion, value in summed_emotions.items()}\n",
    "\n",
    "    # Convert the dictionary to a DataFrame row\n",
    "    return pd.DataFrame([mean_emotions])\n",
    "\n",
    "# Apply the function to every row in the entities_and_emotions DataFrame\n",
    "emotions_df = pd.concat(entities_and_emotions.apply(lambda row: extract_emotions(row)).tolist(), ignore_index=True)\n",
    "\n",
    "# Replace NaN values with 0 if necessary\n",
    "emotions_df.replace(np.nan, 0, inplace=True)\n",
    "emotions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the extract_emotions function to work with entities\n",
    "def extract_emotions_by_entity(row):\n",
    "    # Initialize an empty dictionary to store sums of emotions per entity\n",
    "    summed_emotions = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    # Loop through each dictionary in the row (list of dictionaries)\n",
    "    for entry in row:\n",
    "        entity = entry['entity']\n",
    "        emotions_dict = entry['emotions']\n",
    "\n",
    "        # Initialize entity emotion tracking if it doesn't exist\n",
    "        if entity not in summed_emotions:\n",
    "            summed_emotions[entity] = {}\n",
    "            count_dict[entity] = 0\n",
    "\n",
    "        # Add up emotion values for the entity, initializing keys if they don't exist yet\n",
    "        for emotion, value in emotions_dict.items():\n",
    "            if emotion in summed_emotions[entity]:\n",
    "                summed_emotions[entity][emotion] += value\n",
    "            else:\n",
    "                summed_emotions[entity][emotion] = value\n",
    "\n",
    "        # Increase the count for the entity\n",
    "        count_dict[entity] += 1\n",
    "\n",
    "    # Calculate the mean for each entity's emotions\n",
    "    mean_emotions = {\n",
    "        entity: {emotion: value / count_dict[entity] for emotion, value in emotions.items()}\n",
    "        for entity, emotions in summed_emotions.items()\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame with each entity's average emotions\n",
    "    return pd.DataFrame([{'entity': entity, **emotions} for entity, emotions in mean_emotions.items()])\n",
    "\n",
    "\n",
    "# Apply the function to every row in the DataFrame\n",
    "tmp = pd.concat(\n",
    "    entities_and_emotions.apply(lambda row: extract_emotions_by_entity(row)).tolist(),\n",
    "    ignore_index=True\n",
    ")\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Final DataFrame Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will prepare our data by adding prefixes to each DataFrame for better identification and then concatenate them into a single final DataFrame. This consolidated DataFrame will allow for easier analysis and export of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Prefixes and Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To differentiate between the various DataFrames we have generated, we will add specific prefixes to each DataFrame. This will help in identifying which columns belong to which sentiment analysis technique or original content. After adding the prefixes, we will compile a list of all the DataFrames and concatenate them into a single DataFrame for streamlined analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gt-NaKjVcdwl"
   },
   "outputs": [],
   "source": [
    "# Add prefixes to each DataFrame\n",
    "final_df = df.add_prefix('original_')  # Prefix for the original df\n",
    "vader_sentiments_df_with_prefix = vader_sentiments_df.add_prefix('vader_')  # Prefix for VADER sentiment\n",
    "finbert_df_with_prefix = finbert_mean_df.add_prefix('finbert_')  # Prefix for FinBERT sentiment\n",
    "summary_df_prefix = summary_df.add_prefix('summary_')\n",
    "emotions_df_with_prefix = emotions_df.add_prefix('emotions_')  # Prefix for emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.shape)\n",
    "print(vader_sentiments_df_with_prefix.shape)\n",
    "print(finbert_df_with_prefix.shape)\n",
    "print(summary_df_prefix.shape)\n",
    "print(emotions_df_with_prefix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WR21gZiV02nk"
   },
   "outputs": [],
   "source": [
    "# List of DataFrames to concatenate\n",
    "dfs = [final_df, vader_sentiments_df_with_prefix, finbert_df_with_prefix, \n",
    "       summary_df_prefix, emotions_df_with_prefix]\n",
    "\n",
    "# Concatenate all DataFrames along axis=1\n",
    "final_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final DataFrame Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After concatenating our DataFrames, we will perform some final processing, including dropping any rows with missing values to ensure the integrity of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OADQVM0Sv-_G"
   },
   "outputs": [],
   "source": [
    "final_df.dropna(inplace=True)\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Xy_J9tGPwBb9"
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(path_or_buf='./final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ofFwmi8KnTGY"
   },
   "outputs": [],
   "source": [
    "# final_df = pd.read_csv('/content/drive/MyDrive/microsoft_articles/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "040072bb05cb45718263349c6e32553c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a273dad4d9f488f9d27af8635d60373": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d1feda31e0b48f0bab76154119288f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a1c131c0b674746875442ca39ed7b28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bc911b864914c5287fc700d1ce16730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d1fb831746c42d7854c5a245ee28144": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_36f37d4f79bf4e28b6af800d5c9903cf",
       "IPY_MODEL_e286e84aac3d4c4cbeb99b45df0dee43",
       "IPY_MODEL_4b5196a128bd4b92a823658cbf77df2b"
      ],
      "layout": "IPY_MODEL_a9dc4d9a4d424da2855ca1e6ad1f8047"
     }
    },
    "36f37d4f79bf4e28b6af800d5c9903cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ace3e49d15104298847646d92c62812b",
      "placeholder": "",
      "style": "IPY_MODEL_6d380ebc441c4ea0bdbb84f215304c9e",
      "value": "config.json:100%"
     }
    },
    "42d269c027b144b1bd3d0687c21e1b27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b5196a128bd4b92a823658cbf77df2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ef661d3874f4301800f26e9475f5306",
      "placeholder": "",
      "style": "IPY_MODEL_0a273dad4d9f488f9d27af8635d60373",
      "value": "533/533[00:00&lt;00:00,7.12kB/s]"
     }
    },
    "5086cb9dd7c24d3789ac77fc1156fe1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd3ec711065b484ba26388808b5f3957",
       "IPY_MODEL_ef54f49ff4b34da899e48aa874661b29",
       "IPY_MODEL_70347210d13b4993a7bb067d5a2e6274"
      ],
      "layout": "IPY_MODEL_6abc1e5f8e5c43859db6696687cb853e"
     }
    },
    "5245a52b848749aea4001aaa7ed0c7aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5faa27c416344c389e1e7e189ee3c334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_daf289c5e6d346d1a494400b37408e8c",
       "IPY_MODEL_b67c432f757c4b9f89221ae74ba1e48d",
       "IPY_MODEL_cfc76ce474dc4b1e9c93981dcdc36753"
      ],
      "layout": "IPY_MODEL_e558af83581f44e78ecc436cccb26eb8"
     }
    },
    "6abc1e5f8e5c43859db6696687cb853e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d380ebc441c4ea0bdbb84f215304c9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70347210d13b4993a7bb067d5a2e6274": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2bb1353bf1c43f2bcde4cda2d28ad33",
      "placeholder": "",
      "style": "IPY_MODEL_7d08c7357c494ec39a2c262272592bb6",
      "value": "439M/439M[00:04&lt;00:00,111MB/s]"
     }
    },
    "7d08c7357c494ec39a2c262272592bb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8dcf8f5e537346cca52d6bd94d058af5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ef661d3874f4301800f26e9475f5306": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9dc4d9a4d424da2855ca1e6ad1f8047": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ace3e49d15104298847646d92c62812b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b061e91a287844829859a88f7f1ad14c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b67c432f757c4b9f89221ae74ba1e48d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5245a52b848749aea4001aaa7ed0c7aa",
      "max": 226122,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d2cdd1056ac6445b9b0b999a214ae1fd",
      "value": 226122
     }
    },
    "b8cf133d61934ed9982ac0a5be2b2d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c2bb1353bf1c43f2bcde4cda2d28ad33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfc76ce474dc4b1e9c93981dcdc36753": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8dcf8f5e537346cca52d6bd94d058af5",
      "placeholder": "",
      "style": "IPY_MODEL_1d1feda31e0b48f0bab76154119288f4",
      "value": "226k/226k[00:00&lt;00:00,2.16MB/s]"
     }
    },
    "d2cdd1056ac6445b9b0b999a214ae1fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "daf289c5e6d346d1a494400b37408e8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b061e91a287844829859a88f7f1ad14c",
      "placeholder": "",
      "style": "IPY_MODEL_040072bb05cb45718263349c6e32553c",
      "value": "vocab.txt:100%"
     }
    },
    "dd3ec711065b484ba26388808b5f3957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff8c2d579232498b9d5ad2e78a737054",
      "placeholder": "",
      "style": "IPY_MODEL_2bc911b864914c5287fc700d1ce16730",
      "value": "pytorch_model.bin:100%"
     }
    },
    "e286e84aac3d4c4cbeb99b45df0dee43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a1c131c0b674746875442ca39ed7b28",
      "max": 533,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b8cf133d61934ed9982ac0a5be2b2d52",
      "value": 533
     }
    },
    "e558af83581f44e78ecc436cccb26eb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5cedb581ef944c2854d3c7ea94139f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef54f49ff4b34da899e48aa874661b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42d269c027b144b1bd3d0687c21e1b27",
      "max": 439101405,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5cedb581ef944c2854d3c7ea94139f0",
      "value": 439101405
     }
    },
    "ff8c2d579232498b9d5ad2e78a737054": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
